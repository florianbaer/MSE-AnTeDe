{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82Ty2ytljwM8"
      },
      "source": [
        "![MSE Logo](https://moodle.msengineering.ch/pluginfile.php/1/core_admin/logo/0x150/1643104191/logo-mse.png)\n",
        "\n",
        "# AnTeDe Lab 4: Search Engine with the Vector Space Model\n",
        "\n",
        "## Summary\n",
        "The aim of this lab is to build a simple document search engine based on TF-IDF document vectors. \n",
        "\n",
        "The lab is inspired by a notebook designed by [Kavita Ganesan](https://github.com/kavgan/nlp-in-practice/blob/master/tf-idf/Keyword%20Extraction%20with%20TF-IDF%20and%20SKlearn.ipynb).\n",
        "\n",
        "<font color='green'>Please answer the questions in green within this notebook, and submit the completed notebook under the corresponding homework on Moodle.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fyyNmytwjwNB",
        "outputId": "5d491eaf-f34f-46dd-ce92-9697fcc006de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.68-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 34.2 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 46.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.1.68 pyahocorasick-1.4.4 textsearch-0.0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-20 19:12:16,166 : INFO : NumExpr defaulting to 2 threads.\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions\n",
        "import os    \n",
        "import nltk  # on Colab, you mind find it helpful to run nltk.download('popular') to install packages\n",
        "import gensim\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from gensim import models, corpora, similarities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Modify path according to your configuration\n",
        "# !ls \"/content/gdrive/MyDrive/ColabNotebooks/MSE_AnTeDe_Spring2022\"\n",
        "import sys\n",
        "sys.path.insert(0,'/content/gdrive/MyDrive/Colab Notebooks/MSE/AnTeDe/MSE_AnTeDe_Lab4')\n",
        "\n",
        "from TextPreprocessor import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icbme5CxknD5",
        "outputId": "a06ad8fd-ce1e-4210-8eed-3705f6388b18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FmrSzZtjwNC"
      },
      "source": [
        "The data used in this lab is a set of 300 documents selected from the Australian Broadcasting Corporation's news mail service. It consists of texts of headline stories from around the years 2000-2001.  This is a shortened version of the Lee Background Corpus [described here](http://www.socsci.uci.edu/~mdlee/lee_pincombe_welsh_document.PDF).  It is available as test data in the **gensim** package, so you do not need to download it separately.\n",
        "\n",
        "The following code will load the documents into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fOAIJSF_jwND"
      },
      "outputs": [],
      "source": [
        "# Code inspired from:\n",
        "# https://github.com/bhargavvader/personal/blob/master/notebooks/text_analysis_tutorial/topic_modelling.ipynb\n",
        "\n",
        "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data'])\n",
        "lee_train_file = test_data_dir + os.sep + 'lee_background.cor'\n",
        "text = open(lee_train_file).read().splitlines()\n",
        "data_df = pd.DataFrame({'text': text})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvTBDFB5jwND"
      },
      "source": [
        "The following code will run our in-house Text Preprocessor provided in the `TextPreprocessor.py` file, and documented in the `MSE_AnTeDe_TextPreprocessingDemo.ipynb` notebook provided in Lab 1 (see Lab 1 archive on Moodle for both files).\n",
        "\n",
        "<font color='green'>Please enrich the following code according your needs (especially stopwords)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ukX1D0nVjwNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67eff5cb-a66e-49af-849e-5c23071c3159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "language = 'english'\n",
        "stop_words = set(stopwords.words(language))\n",
        "# Extend the list here:\n",
        "# TextPreprocessor? - get help regarding the attributes\n",
        "\n",
        "processor = TextPreprocessor(\n",
        "# Add options here:\n",
        " language = language,\n",
        " stopwords = stop_words\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4UyPrWnsjwNE"
      },
      "outputs": [],
      "source": [
        "data_df['processed'] = processor.transform(data_df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kc_rYNwgjwNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a993db00-7cab-4a7b-921d-b256d0cb2ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new report suggests cost age australian population exaggerated report issue australia institute say detailed examination population health data show age population create unsustainable burden shrink workforce far economic social burden found majority old people enjoy healthy independent life many make financial contribution family participate voluntary community activity paper challenge assumption old population see health cost rise unsustainable level say rise health cost cause mainly factor age growth medical technology rise consumer demand escalate price\n"
          ]
        }
      ],
      "source": [
        "print(data_df['processed'].iloc[136])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEGGZXPAjwNG"
      },
      "source": [
        "## Generation of document vectors with [Scikit-learn](https://scikit-learn.org/stable)\n",
        "\n",
        "We will use the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) class from scikit-learn to create a vocabulary and generate word counts or *Term Frequencies* (TF).\n",
        "    \n",
        "The result is a  matrix representation of the counts: each column represents a _word_ in the vocabulary and each row represents a document in our dataset: the cell values are the word counts of the word in the document. \n",
        "\n",
        "The matrix is very sparse, because all words not appearing in a document have 0 counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kCsQWtPQjwNG"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer(max_features=3000) # keep only the 3000 most frequent words in the corpus\n",
        "word_count_vector = cv.fit_transform(data_df['processed'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7UahtJejwNH"
      },
      "source": [
        "Let's look at some words from our vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZvdydbQqjwNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1223e514-be00-4ca8-db96-eb2ed5be0c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "feature_names = cv.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "dPw2YvGbjwNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b095b79-1cd0-4134-a6b0-37682b5df67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n",
            "['title', 'today', 'todd', 'toddler', 'together']\n",
            "1264\n"
          ]
        }
      ],
      "source": [
        "print(len(feature_names)) # has the max_features value been reached?\n",
        "print(feature_names[2700:2705]) # try various slices\n",
        "print(feature_names.index('hundred')) # find a word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nos-sSRjwNI"
      },
      "source": [
        "**TfidfTransformer to Compute Inverse Document Frequency (IDF)**\n",
        "\n",
        "We now use the (sparse) matrix generated by `CountVectorizer` to compute the IDF values of each word.  Note that the IDF should in reality be based on a large and representative corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vA5Jwlb2jwNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050c546d-153b-4439-d2ca-3dcbf7e22d92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer()"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
        "tfidf_transformer.fit(word_count_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtetzPjJjwNI"
      },
      "source": [
        "The IDF values are stored in the `idf_` field of the `TfidfTransformer`.  It has the same size as the array of feature names (words)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "JaHSc6CXjwNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4e4256-5c88-4453-cb68-52812e818ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n",
            "3.711377991194885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "print(len(tfidf_transformer.idf_)) # check length\n",
        "print(tfidf_transformer.idf_[cv.get_feature_names().index('hundred')]) # check IDF value of a word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_JGOWNYjwNJ"
      },
      "source": [
        "**We define here two helper functions:**\n",
        " * the first one is a sorting function for the columns of a sparse matrix in COOrdinate format (a.k.a \"ijv\" or \"triplet\" format [explained here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html));\n",
        " * the second one extracts the feature names (*words*) and their TF-IDF values from the sorted list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tkll9iSijwNJ"
      },
      "outputs": [],
      "source": [
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    \"\"\"get the feature names and tf-idf score of top n items from sorted list\"\"\"\n",
        "    \n",
        "    #use only topn items from vector\n",
        "    sorted_items = sorted_items[:topn]\n",
        "\n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "\n",
        "    for idx, score in sorted_items:\n",
        "        fname = feature_names[idx]\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        "\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNuSsdvOjwNK"
      },
      "source": [
        "We now select a document for which we will generate TF-IDF values.  <font color=\"green\">Please select a random document of your choice between 0 and 300.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "NSJ0wWvajwNK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76091c9b-4640-4d6c-9cf1-dae015803749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Australia will be looking to score quickly today to set South Africa a challenging victory target on day four of the first cricket Test in Adelaide. The Australians will resume their second innings at 0 for 3, an overall lead of 68. South Africa was dismissed late yesterday for 374 with Shane Warne taking five wickets for the 20th time in his Test career. Warne says Australia is well placed to win. \"I was very happy with our position in the match, 10 wickets in hand and 70 runs ahead on a pitch that's deteriorating. I think I'd much rather be in our shoes than theirs,\" he said. But he says Australia will need to bat well today. \"South Africa can come out and bowl us out for 150 and suddenly they're chasing 200, or we can make 200 to 250 and they need 300. It's going to be a great last two days.\" \n",
            "australia look score quickly today set south africa challenge victory target day four first cricket test adelaide australian resume second inning overall lead 68. south africa dismiss late yesterday shane warne take five wicket 20th time test career warne say australia well place win `` happy position match wicket hand run ahead pitch deteriorate think would much rather shoe '' say say australia need bat well today `` south africa come bowl u suddenly chase make need 300. go great last two day ''\n"
          ]
        }
      ],
      "source": [
        "# doc_orig = data_df['text'].iloc[136]\n",
        "# doc_processed = data_df['processed'].iloc[136]\n",
        "doc_orig = data_df['text'].iloc[139]\n",
        "doc_processed = data_df['processed'].iloc[139]\n",
        "print(doc_orig)\n",
        "print(doc_processed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70AZuMwEjwNK"
      },
      "source": [
        "**The next instruction generates the vector of TF-IDF values for the document** using the `tfidf_transformer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E6QDog81jwNL"
      },
      "outputs": [],
      "source": [
        "tf_idf_vector = tfidf_transformer.transform(cv.transform([doc_processed]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uai2CaKgjwNL"
      },
      "source": [
        "Next, we sort the words in the `tf_idf_vector` by decreasing TF-IDF values, first transforming the vector into a coordinate format ('coo'), and then applying our sorting function from above.  We then extract the words with the top 10 scores (and the scores) for the selected document using our second helper function from above and display them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HzpxvDcPjwNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73fc37be-b8a5-440d-a302-125db566ee2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Australia will be looking to score quickly today to set South Africa a challenging victory target on day four of the first cricket Test in Adelaide. The Australians will resume their second innings at 0 for 3, an overall lead of 68. South Africa was dismissed late yesterday for 374 with Shane Warne taking five wickets for the 20th time in his Test career. Warne says Australia is well placed to win. \"I was very happy with our position in the match, 10 wickets in hand and 70 runs ahead on a pitch that's deteriorating. I think I'd much rather be in our shoes than theirs,\" he said. But he says Australia will need to bat well today. \"South Africa can come out and bowl us out for 150 and suddenly they're chasing 200, or we can make 200 to 250 and they need 300. It's going to be a great last two days.\"  \n",
            " {'africa': 0.322, 'warne': 0.253, 'wicket': 0.235, 'south': 0.201, 'test': 0.19, 'australia': 0.188, 'need': 0.17, 'well': 0.155, 'suddenly': 0.153, 'deteriorate': 0.153}\n"
          ]
        }
      ],
      "source": [
        "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "topn_words = extract_topn_from_vector(feature_names, sorted_items, 10)\n",
        "\n",
        "print(doc_orig, '\\n', topn_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH5HU1KRjwNL"
      },
      "source": [
        "<font color=\"green\">Please comment briefly on the relevance of these words with respect to the document content.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The words with a higher tf-idf value are less common across all the documents but have a higher influence to the currently open document at index 139 (which was choosen by me)"
      ],
      "metadata": {
        "id": "A2D_4R0WqI45"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfxN7bsDjwNL"
      },
      "source": [
        "## Document-document similarity using scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTMJfTVZjwNL"
      },
      "source": [
        "In this section, you will write the commands to compute a document-document similarity matrix over the above documents, in scikit-learn.\n",
        "\n",
        "Please use a processing [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) and a [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and compute the *cosine similarities* between all documents.  \n",
        "\n",
        "<font color=\"green\">At the end, you will be asked to display the five most similar documents to the one you selected above, and compare the 1st and the 5th best results.</font>\n",
        "\n",
        "You can use inspiration from: \n",
        " * the above code\n",
        " * https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.XkK2ceFCe-Y\n",
        " * https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n",
        " * https://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity\n",
        " * https://markhneedham.com/blog/2016/07/27/scitkit-learn-tfidf-and-cosine-similarity-for-computer-science-papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PnH7Zeb5jwNM"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5bxuvTMojwNM"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(use_idf=True)\n",
        "pipe = Pipeline(steps=[('pre', processor), ('tfidf', tfidf)]) # the 'processor' was defined above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-Jv4fs3jwNM"
      },
      "source": [
        "<font color='green'>Please write a function called `find_similar` which receives a `tfidf_matrix` with all similarity scores between documents, and the `index` of a document in the collection, and returns the `top_n` most similar documents to it using cosine similarity.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2pSdpUrljwNM"
      },
      "outputs": [],
      "source": [
        "def find_similar(tfidf_matrix, index, top_n = 5):\n",
        "    cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "    \n",
        "    return cosine_similarities[index].argsort()[:-top_n-2:-1][1:]\n",
        "    #return [(index, cosine_similarities[index]) for index in related_docs_indices][0:top_n]\n",
        "    #indices = \n",
        "    #return indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbGa-ZQLjwNM"
      },
      "source": [
        "<font color=\"green\">Using the data from the Pandas form created above, please use \"fit\" and \"transform\" to generate the matrix of all document similarites called \"tfidf_matrix\". -- How long do these two operations take on your computer?  -- Please explain briefly in your own words what is the difference between \"fit\" and \"transform\".</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nP1bzuhRjwNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e7485d-99bd-47b4-9ba8-7944aa7a8767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transform and fit done in 19.300696849822998\n",
            "(300, 5551)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "tfidf_matrix = pipe.fit_transform(data_df['text'])\n",
        "\n",
        "end = time.time()\n",
        "print(f'transform and fit done in {end - start}')\n",
        "\n",
        "print(tfidf_matrix.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With `fit` the model is being created and with transform the vectorizer is used and applied to the data."
      ],
      "metadata": {
        "id": "neTrrox1oAJX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0YxXzpijwNN"
      },
      "source": [
        "<font color=\"green\">Using `find_similar` and the `tfidf_matrix` please display the five most similar documents to the one you selected above, with their scores, comment them, and compare the 1st and the 5th best results.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WztY9oLOjwNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c377143e-3ca8-4127-9ef4-a9a5b7ef40c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([132, 182, 118, 112, 104])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "find_similar(tfidf_matrix, 139, top_n = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeMA7irHjwNN"
      },
      "source": [
        "<font color='green'>Could you also use the dot product instead of the cosine similarity in the `find_similar` function?  Please answer in the following box.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Thgc5GSVjwNN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59a5d4ed-852c-4449-b013-424ed57656c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nNo - as it only compares if two given words are occuring together in different documents. It can not distinguish which word it is as it sums up the products of words\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "'''\n",
        "No - as it only compares if two given words are occuring together in different documents. It can not distinguish which word it is as it sums up the products of words\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGchqFMYjwNN"
      },
      "source": [
        "## Building a search engine using Gensim\n",
        "\n",
        "<font color='green'>Using the [tutorial on Topics and Transformations from Gensim](https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html#sphx-glr-auto-examples-core-run-topics-and-transformations-py), please implement a method that returns the documents most similar to a given query.\n",
        "    \n",
        "Use [Gensim's TF-IDF Model](https://radimrehurek.com/gensim/models/tfidfmodel.html) to build the model and the [MatrixSimilarity function](https://radimrehurek.com/gensim/similarities/docsim.html#gensim.similarities.docsim.MatrixSimilarity) to measure cosine similarity between documents.</font>\n",
        "\n",
        "<font color='green'>Please write a query of your own (5-10 words), retrieve the 5 most similar documents, and comment the result.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Cr1q6ChFjwNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ae038e-5198-4cce-f6fe-af4c9f1083b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-20 20:56:26,951 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2022-03-20 20:56:27,031 : INFO : built Dictionary(5443 unique tokens: ['across', 'aedt', 'area', 'around', 'associate']...) from 300 documents (total 34244 corpus positions)\n",
            "2022-03-20 20:56:27,097 : INFO : collecting document frequencies\n",
            "2022-03-20 20:56:27,100 : INFO : PROGRESS: processing document #0\n",
            "2022-03-20 20:56:27,114 : INFO : calculating IDF weights for 300 documents and 5442 features (25035 matrix non-zeros)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TfidfModel(num_docs=300, num_nnz=25035)\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "from gensim import models\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "doc_tokenized = [simple_preprocess(doc) for doc in data_df['processed']]\n",
        "dictionary = corpora.Dictionary(doc_tokenized)\n",
        "corpus = [dictionary.doc2bow(text) for text in doc_tokenized]\n",
        "\n",
        "model = models.TfidfModel(corpus)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "BUNAxR8-jwNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0b7353-e977-481c-a309-73ac279dac23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-20 21:03:10,708 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
            "2022-03-20 21:03:10,934 : INFO : creating matrix with 300 documents and 5443 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(112, 0.10040326416492462), (104, 0.10040326416492462), (146, 0.07662541419267654), (150, 0.07574578374624252), (156, 0.07574578374624252)]\n",
            "Similarity 0.10040326416492462 112 : australian cricket captain steve waugh support fast bowler brett lee criticism intimidatory bowling south african tailenders first test adelaide earlier month lee fin give new zealand tailender shane bond send-off third test perth waugh say tailenders protect short-pitched bowling `` day earn big money get responsibility learn bat '' say `` mean time like year ago professional sort bowler code `` day professional batsman work hard batting expect tailenders likewise '' meanwhile waugh say side need guard complacency convincingly win first test run waugh say despite dominance side first test south africa never take lightly `` one test match three six whichever way want look lot work go '' say `` nice win first battle definitely give u lot confidence go melbourne know big crowd love play front boxing day crowd advantage well '' south africa begin four-day match new south wale sydney thursday lead boxing day test veteran fast bowler allan donald play warm-up match likely take place team second test south african captain shaun pollock expect much well performance side melbourne test `` still believe play full potential improve aspect ... output put field lot well still believe side good enough beat australia day '' say\n",
            "Similarity 0.10040326416492462 104 : australian cricket captain steve waugh support fast bowler brett lee criticism intimidatory bowling south african tailenders first test adelaide earlier month lee fin give new zealand tailender shane bond send-off third test perth waugh say tailenders protect short-pitched bowling `` day earn big money get responsibility learn bat '' say `` mean time like year ago professional sort bowler code `` day professional batsman work hard batting expect tailenders likewise '' meanwhile waugh say side need guard complacency convincingly win first test run waugh say despite dominance side first test south africa never take lightly `` one test match three six whichever way want look lot work go '' say `` nice win first battle definitely give u lot confidence go melbourne know big crowd love play front boxing day crowd advantage well '' south africa begin four-day match new south wale sydney thursday lead boxing day test veteran fast bowler allan donald play warm-up match likely take place team second test south african captain shaun pollock expect much well performance side melbourne test `` still believe play full potential improve aspect ... output put field lot well still believe side good enough beat australia day '' say\n",
            "Similarity 0.07662541419267654 146 : australian south african side first cricket test start adelaide oval today expect finalise start play australian captain steve waugh south african counterpart shaun pollock decide lineup inspection pitch shortly start play match hold special significance waugh twin brother mark play 100th test together steve waugh place much relevance milestone `` want read much guess get carry away later retire look back significant `` nice family mum dad sacrifice make know u grow also brother know nice family '' say\n",
            "Similarity 0.07574578374624252 150 : industrial action affect three australia 's big bank next two day banking staff westpac national australia bank strike today hour worker anz follow suit tomorrow action member finance sector union time coincide bank annual general meeting part ongoing enterprise bargaining negotiation union 's geoff derrick say strike pay `` certainly pay 's need key issue u around workload `` get million hour overtime work week industry unpaid '' mr derrick say westpac 's david lord say today 's action unjustified `` per cent pay increase two year eligible staff table generous pay offer `` would also like introduce number initiative assist staff balance particular work family life would like deal union '' mr lord say `` would like union come back negotiate table rather continue pr stunt '' mr lord say contingency plan place ensure branch stay open `` hop offer normal banking service customer '' say\n",
            "Similarity 0.07574578374624252 156 : industrial action affect three australia 's big bank next two day banking staff westpac national australia bank strike today hour worker anz follow suit tomorrow action member finance sector union time coincide bank annual general meeting part ongoing enterprise bargaining negotiation union 's geoff derrick say strike pay `` certainly pay 's need key issue u around workload `` get million hour overtime work week industry unpaid '' mr derrick say westpac 's david lord say today 's action unjustified `` per cent pay increase two year eligible staff table generous pay offer `` would also like introduce number initiative assist staff balance particular work family life would like deal union '' mr lord say `` would like union come back negotiate table rather continue pr stunt '' mr lord say contingency plan place ensure branch stay open `` hop offer normal banking service customer '' say\n"
          ]
        }
      ],
      "source": [
        "from gensim.similarities import MatrixSimilarity\n",
        "\n",
        "doc = \"I love sports very much but i don't like cricket.\"\n",
        "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
        "sims = model[vec_bow]\n",
        "index = MatrixSimilarity(model[corpus], num_best=5)\n",
        "\n",
        "sims = index[sims]\n",
        "print(sims)\n",
        "for sim, similarity in sims:\n",
        "    print(f'Similarity {similarity} {sim} : ' + data_df['processed'].iloc[sim])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdi-5wOsjwNO"
      },
      "source": [
        "## End of Lab 4\n",
        "Please make sure all cells have been executed, save this completed notebook, compress it to a *zip* file, and upload it to [Moodle](https://moodle.msengineering.ch/course/view.php?id=1869)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0_lGn6aEv71A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cours",
      "language": "python",
      "name": "cours"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MSE_AnTeDe_Lab4_Search_Engine_Florian_Bär.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}