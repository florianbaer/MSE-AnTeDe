{"cells":[{"cell_type":"markdown","metadata":{"id":"2jx_nG_SbzYd"},"source":["# AnTeDe Lab 3: Sentiment Analysis - Part C\n","\n","## Session goal\n","The goal of this session is to run document-level sentiment analysis on the IMDB movie review corpus by applying supervised text classification techniques. We begin by wrangling the IMBD corpus into lists, exactly like in 3b."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eS36SRf8bzYi","executionInfo":{"status":"ok","timestamp":1647094858475,"user_tz":-60,"elapsed":4884,"user":{"displayName":"Florian Bär","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438539089054973879"}},"outputId":"d916c1ce-41d7-4f60-b854-0e7951aa7925"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"]}],"source":["import random, nltk\n","from nltk.corpus import movie_reviews\n","nltk.download('movie_reviews')\n","corpus = [' '.join(movie_reviews.words(fileid)) \\\n","          for category in movie_reviews.categories() \\\n","          for fileid in movie_reviews.fileids(category)]\n","\n","labels = [category \\\n","          for category in movie_reviews.categories() \\\n","          for fileid in movie_reviews.fileids(category)]"]},{"cell_type":"markdown","metadata":{"id":"VOS8dPVWbzYk"},"source":["**scikit-learn** enables us the split the corpus into a training corpus and a test corpus. The parameter *test-size* is the desired ratio of the test corpus size to the training corpus size. The paramenter *random_state* ensures reproducibility."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"oqDrxiOcbzYl","executionInfo":{"status":"ok","timestamp":1647094861613,"user_tz":-60,"elapsed":213,"user":{"displayName":"Florian Bär","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438539089054973879"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","training_corpus, test_corpus, training_labels, test_labels = train_test_split(\n","        corpus, labels, test_size=0.2, random_state=21)"]},{"cell_type":"markdown","metadata":{"id":"JMnNNSsgbzYm"},"source":["We reuse our helper function **get_metrics** from Lab 2."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6Ljb96o3bzYm","executionInfo":{"status":"ok","timestamp":1647094865900,"user_tz":-60,"elapsed":3,"user":{"displayName":"Florian Bär","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438539089054973879"}}},"outputs":[],"source":["def get_metrics(true_labels, predicted_labels):\n","        from sklearn import metrics\n","        import numpy as np\n","        print ('Accuracy:', np.round(\n","            metrics.accuracy_score(true_labels,\n","            predicted_labels), 3))\n","        \n","        from sklearn.metrics import classification_report\n","        print(classification_report(test_labels, predicted_labels))"]},{"cell_type":"markdown","metadata":{"id":"82hwg-RLbzYo"},"source":["Now we are going to use a MNB classifier for sentiment analysis. **CountVectorizer**'s parameter **binary** replaces token counts with binary values if set to True. In sentiment analysis, the number of occurrences of a token may not be as important as its presence or absence, so setting it to True may be a good idea, but let's perform 10-fold cross-validation to find out whether it really is. We want the mean to be as high as possible and the standard deviation to be as low as possible. "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1153tOujbzYp","executionInfo":{"status":"ok","timestamp":1647095032458,"user_tz":-60,"elapsed":7921,"user":{"displayName":"Florian Bär","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438539089054973879"}},"outputId":"458c6379-e3ba-4c05-9a6a-3212705a8f4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.802\n","0.023\n"]}],"source":["from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","\n","mnb_pipeline_1 = Pipeline([ ('vectorizer', CountVectorizer(binary = False, stop_words='english')),\\\n","                ('classifier', MultinomialNB())])  \n","    \n","scores = cross_val_score(mnb_pipeline_1, training_corpus, training_labels, cv=10)\n","import numpy as np\n","print (round(np.mean(scores), 3))\n","print (round(np.std(scores), 3))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNXz3edVbzYr","executionInfo":{"status":"ok","timestamp":1647095040317,"user_tz":-60,"elapsed":7879,"user":{"displayName":"Florian Bär","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438539089054973879"}},"outputId":"5e554c99-b029-4ebd-bc3c-27506a9abae3"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.833\n","0.028\n"]}],"source":["from sklearn.model_selection import cross_val_score\n","\n","mnb_pipeline_2 = Pipeline([ ('vectorizer', CountVectorizer(binary = True, stop_words='english')),\\\n","                ('classifier', MultinomialNB())])  \n","    \n","scores = cross_val_score(mnb_pipeline_2, training_corpus, training_labels, cv=10)\n","import numpy as np\n","print (round(np.mean(scores), 3))\n","print (round(np.std(scores), 3))"]},{"cell_type":"markdown","metadata":{"id":"uwik2YSDbzYt"},"source":["Based on your 10-fold cross-validation results, choose one of the two pipelines, train it, run it, and analyze its performance."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VkSjYIRWbzYt","executionInfo":{"status":"ok","timestamp":1647095107866,"user_tz":-60,"elapsed":1032,"user":{"displayName":"Florian Bär","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438539089054973879"}},"outputId":"ab09dc88-2b18-460a-f0f3-9d2059018b12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.825\n","              precision    recall  f1-score   support\n","\n","         neg       0.83      0.81      0.82       198\n","         pos       0.82      0.84      0.83       202\n","\n","    accuracy                           0.82       400\n","   macro avg       0.83      0.82      0.82       400\n","weighted avg       0.83      0.82      0.82       400\n","\n"]}],"source":["# BEGIN_REMOVE\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","\n","mnb_pipeline_2.fit(training_corpus, training_labels) \n","predicted_labels = mnb_pipeline_2.predict(test_corpus)\n","get_metrics(true_labels=test_labels,\n","        predicted_labels=predicted_labels)\n","# END_REMOVE"]},{"cell_type":"markdown","metadata":{"id":"e5d6PsaMbzYu"},"source":["Now let's train a Maximum Entropy classifier using the **LogisticRegression** module from **scikit-learn**. Please complete the code to train and run the classifier."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuqDbfOMbzYv","executionInfo":{"status":"ok","timestamp":1647095202222,"user_tz":-60,"elapsed":1908,"user":{"displayName":"Florian Bär","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438539089054973879"}},"outputId":"2d63ef47-1e01-42b4-bc7b-524d76ff6793"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.83\n","              precision    recall  f1-score   support\n","\n","         neg       0.85      0.80      0.82       198\n","         pos       0.82      0.86      0.84       202\n","\n","    accuracy                           0.83       400\n","   macro avg       0.83      0.83      0.83       400\n","weighted avg       0.83      0.83      0.83       400\n","\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import make_pipeline\n","\n","vectorizer = CountVectorizer(binary = True, stop_words='english')\n","classifier = LogisticRegression()\n","maxent_pipeline = make_pipeline(vectorizer, classifier)\n","\n","\n","# BEGIN_REMOVE\n","maxent_pipeline.fit(training_corpus, training_labels) \n","predicted_labels = maxent_pipeline.predict(test_corpus)\n","get_metrics(true_labels=test_labels,\n","        predicted_labels=predicted_labels)\n","# END_REMOVE"]},{"cell_type":"markdown","metadata":{"id":"FFrtLQXDbzYw"},"source":["With **eli5**, you can get some insights into the most informative words in your corpus."]},{"cell_type":"code","execution_count":12,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":507},"id":"VMrhX_35bzYw","executionInfo":{"status":"ok","timestamp":1647095269430,"user_tz":-60,"elapsed":220,"user":{"displayName":"Florian Bär","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438539089054973879"}},"outputId":"8e79bb66-501c-4a97-f090-ca822f5db7b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","            \n","                \n","                \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=pos\n","    \n","</b>\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n","                    Weight<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 83.76%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.628\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        memorable\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 84.66%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.579\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        hilarious\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 85.35%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.542\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        overall\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 85.95%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.511\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        terrific\n","    </td>\n","    \n","</tr>\n","        \n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 85.95%); border: none;\">\n","                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n","                    <i>&hellip; 18550 more positive &hellip;</i>\n","                </td>\n","            </tr>\n","        \n","\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 85.76%); border: none;\">\n","                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n","                    <i>&hellip; 17407 more negative &hellip;</i>\n","                </td>\n","            </tr>\n","        \n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 85.76%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.520\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        poor\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 85.70%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.523\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        cheap\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 85.28%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.545\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        wasted\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 85.15%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.553\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        plot\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 85.05%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.558\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        mess\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 84.91%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.565\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        ridiculous\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 84.67%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.578\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        supposed\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 84.58%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.583\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        reason\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 84.50%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.588\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        script\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 83.94%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.618\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        awful\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 83.86%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.622\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        unfortunately\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 83.08%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.665\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        boring\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 82.19%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.716\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        waste\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 82.10%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.721\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        worst\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 81.49%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.757\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.845\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        bad\n","    </td>\n","    \n","</tr>\n","        \n","\n","        </tbody>\n","    </table>\n","\n","            \n","        \n","\n","        \n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"]},"metadata":{},"execution_count":12}],"source":["# !pip install eli5\n","import eli5\n","eli5.show_weights(classifier, vec=vectorizer, top=20)\n"]},{"cell_type":"markdown","metadata":{"id":"du84hl5abzYx"},"source":["You can also explore your corpus and find out which specific tokens drove the classifier's decisions. Change the value of *item* to visualize what happened in each test sample."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"Vy4rISqXbzYx","executionInfo":{"status":"ok","timestamp":1647095332425,"user_tz":-60,"elapsed":542,"user":{"displayName":"Florian Bär","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438539089054973879"}},"outputId":"58a5af3d-fe31-4e0f-f669-b9ebfbfc31d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction: pos; groud truth: pos\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=pos\n","    \n","</b>\n","\n","    \n","    (probability <b>0.936</b>, score <b>2.679</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +3.436\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 93.07%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.757\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"opacity: 0.80\">the </span><span style=\"background-color: hsl(0, 100.00%, 92.88%); opacity: 0.82\" title=\"-0.061\">1990s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.07%); opacity: 0.81\" title=\"-0.036\">produced</span><span style=\"opacity: 0.80\"> two </span><span style=\"background-color: hsl(120, 100.00%, 77.08%); opacity: 0.89\" title=\"0.326\">brilliant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.14%); opacity: 0.83\" title=\"-0.112\">science</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.80%); opacity: 0.82\" title=\"0.088\">fiction</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.98%); opacity: 0.81\" title=\"0.027\">films</span><span style=\"opacity: 0.80\"> . one was _gattaca_ . the other was </span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.005\">_the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.60%); opacity: 0.80\" title=\"0.006\">thirteenth</span><span style=\"opacity: 0.80\"> floor_ . </span><span style=\"background-color: hsl(120, 100.00%, 98.38%); opacity: 0.80\" title=\"0.007\">just</span><span style=\"opacity: 0.80\"> as _gattaca_ was </span><span style=\"background-color: hsl(0, 100.00%, 97.54%); opacity: 0.80\" title=\"-0.013\">overshadowed</span><span style=\"opacity: 0.80\"> by the </span><span style=\"background-color: hsl(0, 100.00%, 98.57%); opacity: 0.80\" title=\"-0.006\">mighty</span><span style=\"opacity: 0.80\"> _titanic_ , </span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.005\">_the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.60%); opacity: 0.80\" title=\"0.006\">thirteenth</span><span style=\"opacity: 0.80\"> floor_ was </span><span style=\"background-color: hsl(0, 100.00%, 93.26%); opacity: 0.82\" title=\"-0.057\">relegated</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 96.21%); opacity: 0.81\" title=\"0.025\">obscurity</span><span style=\"opacity: 0.80\"> by </span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.005\">_the</span><span style=\"opacity: 0.80\"> matrix_ . however , </span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.005\">_the</span><span style=\"opacity: 0.80\"> thirteeth floor_ , though it </span><span style=\"background-color: hsl(0, 100.00%, 82.31%); opacity: 0.86\" title=\"-0.225\">deals</span><span style=\"opacity: 0.80\"> with </span><span style=\"background-color: hsl(120, 100.00%, 89.83%); opacity: 0.83\" title=\"0.102\">similar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.63%); opacity: 0.85\" title=\"0.167\">themes</span><span style=\"opacity: 0.80\"> , is a much </span><span style=\"background-color: hsl(0, 100.00%, 78.96%); opacity: 0.88\" title=\"-0.288\">better</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.001\">movie</span><span style=\"opacity: 0.80\"> than the </span><span style=\"background-color: hsl(0, 100.00%, 97.49%); opacity: 0.80\" title=\"-0.014\">frenetic</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 94.49%); opacity: 0.81\" title=\"-0.042\">childish</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 98.08%); opacity: 0.80\" title=\"-0.009\">improbable</span><span style=\"opacity: 0.80\"> _matrix_ . a </span><span style=\"background-color: hsl(120, 100.00%, 91.52%); opacity: 0.82\" title=\"0.079\">cutting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.47%); opacity: 0.82\" title=\"0.066\">edge</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.05%); opacity: 0.82\" title=\"0.085\">computer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.41%); opacity: 0.83\" title=\"0.108\">scientist</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 99.97%); opacity: 0.80\" title=\"0.000\">hannon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.78%); opacity: 0.80\" title=\"0.012\">fuller</span><span style=\"opacity: 0.80\"> ( </span><span style=\"background-color: hsl(0, 100.00%, 93.28%); opacity: 0.82\" title=\"-0.056\">played</span><span style=\"opacity: 0.80\"> by the </span><span style=\"background-color: hsl(120, 100.00%, 89.92%); opacity: 0.83\" title=\"0.101\">charming</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.95%); opacity: 0.80\" title=\"-0.010\">armin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.84%); opacity: 0.80\" title=\"-0.011\">mueller</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(0, 100.00%, 95.52%); opacity: 0.81\" title=\"-0.032\">stahl</span><span style=\"opacity: 0.80\"> ) , is </span><span style=\"background-color: hsl(0, 100.00%, 92.39%); opacity: 0.82\" title=\"-0.067\">murdered</span><span style=\"opacity: 0.80\"> . his </span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.006\">associate</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 98.02%); opacity: 0.80\" title=\"-0.010\">douglas</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.64%); opacity: 0.81\" title=\"0.021\">hall</span><span style=\"opacity: 0.80\"> , ( </span><span style=\"background-color: hsl(0, 100.00%, 90.98%); opacity: 0.82\" title=\"-0.086\">craig</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.04%); opacity: 0.80\" title=\"-0.003\">bierko</span><span style=\"opacity: 0.80\"> ) </span><span style=\"background-color: hsl(0, 100.00%, 81.15%); opacity: 0.87\" title=\"-0.246\">apparently</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.92%); opacity: 0.80\" title=\"0.004\">framed</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(120, 100.00%, 95.49%); opacity: 0.81\" title=\"0.032\">suspected</span><span style=\"opacity: 0.80\"> by the </span><span style=\"background-color: hsl(0, 100.00%, 92.22%); opacity: 0.82\" title=\"-0.070\">police</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 92.67%); opacity: 0.82\" title=\"0.064\">enters</span><span style=\"opacity: 0.80\"> into the </span><span style=\"background-color: hsl(0, 100.00%, 96.22%); opacity: 0.81\" title=\"-0.025\">simulated</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.86%); opacity: 0.82\" title=\"0.074\">world</span><span style=\"opacity: 0.80\"> they have </span><span style=\"background-color: hsl(120, 100.00%, 97.81%); opacity: 0.80\" title=\"0.011\">created</span><span style=\"opacity: 0.80\"> in </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.020\">order</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 95.90%); opacity: 0.81\" title=\"0.028\">unravel</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 97.73%); opacity: 0.80\" title=\"0.012\">mystery</span><span style=\"opacity: 0.80\"> . along the </span><span style=\"background-color: hsl(120, 100.00%, 91.38%); opacity: 0.82\" title=\"0.080\">way</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 86.00%); opacity: 0.84\" title=\"0.161\">beautiful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.61%); opacity: 0.81\" title=\"-0.031\">blonde</span><span style=\"opacity: 0.80\"> ( </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.027\">gretchen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.48%); opacity: 0.80\" title=\"0.014\">mol</span><span style=\"opacity: 0.80\"> ) , more </span><span style=\"background-color: hsl(120, 100.00%, 89.29%); opacity: 0.83\" title=\"0.110\">bodies</span><span style=\"opacity: 0.80\"> , and a </span><span style=\"background-color: hsl(120, 100.00%, 97.64%); opacity: 0.80\" title=\"0.013\">deepening</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.73%); opacity: 0.80\" title=\"0.012\">mystery</span><span style=\"opacity: 0.80\"> about </span><span style=\"background-color: hsl(0, 100.00%, 96.22%); opacity: 0.81\" title=\"-0.025\">simulated</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.85%); opacity: 0.82\" title=\"0.062\">worlds</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.16%); opacity: 0.80\" title=\"0.016\">complicate</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 83.36%); opacity: 0.86\" title=\"0.206\">picture</span><span style=\"opacity: 0.80\"> . </span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.005\">_the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.60%); opacity: 0.80\" title=\"0.006\">thirteenth</span><span style=\"opacity: 0.80\"> floor_ </span><span style=\"background-color: hsl(120, 100.00%, 89.36%); opacity: 0.83\" title=\"0.109\">unfolds</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.96%); opacity: 0.81\" title=\"0.048\">slowly</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 96.54%); opacity: 0.81\" title=\"-0.022\">telegraphs</span><span style=\"opacity: 0.80\"> its </span><span style=\"background-color: hsl(0, 100.00%, 95.25%); opacity: 0.81\" title=\"-0.034\">punches</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 88.28%); opacity: 0.83\" title=\"-0.125\">choosing</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(0, 100.00%, 90.43%); opacity: 0.83\" title=\"-0.094\">elicit</span><span style=\"opacity: 0.80\"> the more </span><span style=\"background-color: hsl(120, 100.00%, 91.36%); opacity: 0.82\" title=\"0.081\">complex</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.76%); opacity: 0.80\" title=\"-0.012\">emotional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.05%); opacity: 0.80\" title=\"0.017\">response</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 94.07%); opacity: 0.81\" title=\"-0.047\">empathy</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 96.11%); opacity: 0.81\" title=\"-0.026\">anticipation</span><span style=\"opacity: 0.80\"> rather than the </span><span style=\"background-color: hsl(0, 100.00%, 68.05%); opacity: 0.95\" title=\"-0.523\">cheap</span><span style=\"opacity: 0.80\"> one of </span><span style=\"background-color: hsl(0, 100.00%, 92.67%); opacity: 0.82\" title=\"-0.064\">mere</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.59%); opacity: 0.87\" title=\"0.238\">surprise</span><span style=\"opacity: 0.80\"> . the </span><span style=\"background-color: hsl(0, 100.00%, 88.65%); opacity: 0.83\" title=\"-0.119\">result</span><span style=\"opacity: 0.80\"> is a </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.001\">movie</span><span style=\"opacity: 0.80\"> that is a </span><span style=\"background-color: hsl(0, 100.00%, 81.44%); opacity: 0.87\" title=\"-0.241\">failure</span><span style=\"opacity: 0.80\"> from two </span><span style=\"background-color: hsl(120, 100.00%, 89.87%); opacity: 0.83\" title=\"0.101\">conventional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.67%); opacity: 0.80\" title=\"0.006\">points</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(120, 100.00%, 84.20%); opacity: 0.85\" title=\"0.191\">view</span><span style=\"opacity: 0.80\"> . first , its </span><span style=\"background-color: hsl(0, 100.00%, 66.81%); opacity: 0.95\" title=\"-0.553\">plot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.79%); opacity: 0.80\" title=\"-0.012\">revelations</span><span style=\"opacity: 0.80\"> can be foreseen if one has </span><span style=\"background-color: hsl(120, 100.00%, 87.73%); opacity: 0.84\" title=\"0.133\">carefully</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.02%); opacity: 0.80\" title=\"0.018\">followed</span><span style=\"opacity: 0.80\"> its </span><span style=\"background-color: hsl(120, 100.00%, 91.36%); opacity: 0.82\" title=\"0.081\">complex</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.15%); opacity: 0.83\" title=\"-0.097\">storyline</span><span style=\"opacity: 0.80\"> . </span><span style=\"background-color: hsl(0, 100.00%, 89.04%); opacity: 0.83\" title=\"-0.113\">second</span><span style=\"opacity: 0.80\"> and more </span><span style=\"background-color: hsl(0, 100.00%, 83.39%); opacity: 0.86\" title=\"-0.206\">seriously</span><span style=\"opacity: 0.80\"> , it </span><span style=\"background-color: hsl(120, 100.00%, 88.99%); opacity: 0.83\" title=\"0.114\">demands</span><span style=\"opacity: 0.80\"> that its </span><span style=\"background-color: hsl(120, 100.00%, 95.03%); opacity: 0.81\" title=\"0.037\">audience</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.60%); opacity: 0.83\" title=\"0.120\">think</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 97.14%); opacity: 0.80\" title=\"-0.017\">feel</span><span style=\"opacity: 0.80\"> . no </span><span style=\"background-color: hsl(0, 100.00%, 77.66%); opacity: 0.89\" title=\"-0.314\">wonder</span><span style=\"opacity: 0.80\"> it </span><span style=\"background-color: hsl(120, 100.00%, 99.42%); opacity: 0.80\" title=\"0.002\">fell</span><span style=\"opacity: 0.80\"> through the </span><span style=\"background-color: hsl(120, 100.00%, 97.45%); opacity: 0.80\" title=\"0.014\">cracks</span><span style=\"opacity: 0.80\"> . done in </span><span style=\"background-color: hsl(120, 100.00%, 96.66%); opacity: 0.81\" title=\"0.021\">film</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.05%); opacity: 0.83\" title=\"0.113\">noir</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.41%); opacity: 0.89\" title=\"-0.319\">style</span><span style=\"opacity: 0.80\"> as a </span><span style=\"background-color: hsl(0, 100.00%, 85.93%); opacity: 0.84\" title=\"-0.162\">murder</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.73%); opacity: 0.80\" title=\"0.012\">mystery</span><span style=\"opacity: 0.80\"> , this is a </span><span style=\"background-color: hsl(120, 100.00%, 96.47%); opacity: 0.81\" title=\"0.023\">relatively</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.39%); opacity: 0.81\" title=\"-0.033\">deep</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.001\">movie</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(120, 100.00%, 98.94%); opacity: 0.80\" title=\"0.004\">functions</span><span style=\"opacity: 0.80\"> on several </span><span style=\"background-color: hsl(120, 100.00%, 99.41%); opacity: 0.80\" title=\"0.002\">levels</span><span style=\"opacity: 0.80\"> . many </span><span style=\"background-color: hsl(120, 100.00%, 91.60%); opacity: 0.82\" title=\"0.078\">audiences</span><span style=\"opacity: 0.80\"> will </span><span style=\"background-color: hsl(0, 100.00%, 87.32%); opacity: 0.84\" title=\"-0.140\">simply</span><span style=\"opacity: 0.80\"> be </span><span style=\"background-color: hsl(120, 100.00%, 98.03%); opacity: 0.80\" title=\"0.010\">bewildered</span><span style=\"opacity: 0.80\"> by it , rather than </span><span style=\"background-color: hsl(120, 100.00%, 92.12%); opacity: 0.82\" title=\"0.071\">engaged</span><span style=\"opacity: 0.80\"> , which is a </span><span style=\"background-color: hsl(0, 100.00%, 92.87%); opacity: 0.82\" title=\"-0.061\">shame</span><span style=\"opacity: 0.80\"> , because this </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.001\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.24%); opacity: 0.80\" title=\"-0.016\">amply</span><span style=\"opacity: 0.80\"> repays a </span><span style=\"background-color: hsl(0, 100.00%, 86.45%); opacity: 0.84\" title=\"-0.154\">little</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.76%); opacity: 0.80\" title=\"-0.012\">emotional</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(120, 100.00%, 93.79%); opacity: 0.81\" title=\"0.050\">intellectual</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.31%); opacity: 0.80\" title=\"-0.015\">investment</span><span style=\"opacity: 0.80\"> . i </span><span style=\"background-color: hsl(120, 100.00%, 87.07%); opacity: 0.84\" title=\"0.144\">recommend</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 89.04%); opacity: 0.83\" title=\"-0.113\">second</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.45%); opacity: 0.83\" title=\"0.108\">viewing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.32%); opacity: 0.84\" title=\"-0.140\">simply</span><span style=\"opacity: 0.80\"> to get the </span><span style=\"background-color: hsl(0, 100.00%, 90.25%); opacity: 0.83\" title=\"-0.096\">flavor</span><span style=\"opacity: 0.80\"> of the </span><span style=\"background-color: hsl(120, 100.00%, 93.13%); opacity: 0.82\" title=\"0.058\">frequent</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.93%); opacity: 0.81\" title=\"-0.018\">ironic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.57%); opacity: 0.82\" title=\"-0.065\">foreshadowing</span><span style=\"opacity: 0.80\"> in the </span><span style=\"background-color: hsl(0, 100.00%, 96.42%); opacity: 0.81\" title=\"-0.023\">opening</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.43%); opacity: 0.86\" title=\"0.223\">parts</span><span style=\"opacity: 0.80\"> of the </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.001\">movie</span><span style=\"opacity: 0.80\"> . </span><span style=\"background-color: hsl(120, 100.00%, 84.35%); opacity: 0.85\" title=\"0.189\">despite</span><span style=\"opacity: 0.80\"> its </span><span style=\"background-color: hsl(120, 100.00%, 97.46%); opacity: 0.80\" title=\"0.014\">philosophical</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.93%); opacity: 0.80\" title=\"0.004\">challenges</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.005\">_the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.60%); opacity: 0.80\" title=\"0.006\">thirteenth</span><span style=\"opacity: 0.80\"> floor_ </span><span style=\"background-color: hsl(0, 100.00%, 99.52%); opacity: 0.80\" title=\"-0.001\">derives</span><span style=\"opacity: 0.80\"> its </span><span style=\"background-color: hsl(0, 100.00%, 97.76%); opacity: 0.80\" title=\"-0.012\">emotional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.47%); opacity: 0.87\" title=\"0.259\">force</span><span style=\"opacity: 0.80\"> from the </span><span style=\"background-color: hsl(120, 100.00%, 93.57%); opacity: 0.81\" title=\"0.053\">love</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.93%); opacity: 0.80\" title=\"-0.004\">story</span><span style=\"opacity: 0.80\"> between </span><span style=\"background-color: hsl(120, 100.00%, 95.91%); opacity: 0.81\" title=\"0.028\">jane</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.78%); opacity: 0.80\" title=\"0.012\">fuller</span><span style=\"opacity: 0.80\"> ( </span><span style=\"background-color: hsl(120, 100.00%, 97.48%); opacity: 0.80\" title=\"0.014\">mol</span><span style=\"opacity: 0.80\"> ) and </span><span style=\"background-color: hsl(0, 100.00%, 98.02%); opacity: 0.80\" title=\"-0.010\">douglas</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.64%); opacity: 0.81\" title=\"0.021\">hall</span><span style=\"opacity: 0.80\"> ( </span><span style=\"background-color: hsl(0, 100.00%, 99.04%); opacity: 0.80\" title=\"-0.003\">bierko</span><span style=\"opacity: 0.80\"> ) , as well as the </span><span style=\"background-color: hsl(120, 100.00%, 98.33%); opacity: 0.80\" title=\"0.008\">close</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.21%); opacity: 0.84\" title=\"0.158\">friendship</span><span style=\"opacity: 0.80\"> between </span><span style=\"background-color: hsl(0, 100.00%, 98.02%); opacity: 0.80\" title=\"-0.010\">douglas</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.64%); opacity: 0.81\" title=\"0.021\">hall</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(120, 100.00%, 99.97%); opacity: 0.80\" title=\"0.000\">hannon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.78%); opacity: 0.80\" title=\"0.012\">fuller</span><span style=\"opacity: 0.80\"> . in that </span><span style=\"background-color: hsl(0, 100.00%, 94.45%); opacity: 0.81\" title=\"-0.043\">sense</span><span style=\"opacity: 0.80\"> it is more </span><span style=\"background-color: hsl(0, 100.00%, 96.31%); opacity: 0.81\" title=\"-0.024\">akin</span><span style=\"opacity: 0.80\"> to _gattaca_ than </span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.005\">_the</span><span style=\"opacity: 0.80\"> matrix_ , which , for all of its </span><span style=\"background-color: hsl(120, 100.00%, 90.40%); opacity: 0.83\" title=\"0.094\">cute</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.46%); opacity: 0.80\" title=\"0.014\">philosophical</span><span style=\"opacity: 0.80\"> byplay , is an </span><span style=\"background-color: hsl(0, 100.00%, 94.74%); opacity: 0.81\" title=\"-0.040\">adolescent</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.001\">movie</span><span style=\"opacity: 0.80\"> with no </span><span style=\"background-color: hsl(0, 100.00%, 97.76%); opacity: 0.80\" title=\"-0.012\">emotional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.77%); opacity: 0.81\" title=\"0.039\">depth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.59%); opacity: 0.84\" title=\"-0.151\">whatsoever</span><span style=\"opacity: 0.80\"> . the </span><span style=\"background-color: hsl(0, 100.00%, 84.47%); opacity: 0.85\" title=\"-0.187\">moment</span><span style=\"opacity: 0.80\"> when </span><span style=\"background-color: hsl(120, 100.00%, 95.91%); opacity: 0.81\" title=\"0.028\">jane</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.78%); opacity: 0.80\" title=\"0.012\">fuller</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.24%); opacity: 0.82\" title=\"-0.057\">confesses</span><span style=\"opacity: 0.80\"> her </span><span style=\"background-color: hsl(120, 100.00%, 93.57%); opacity: 0.81\" title=\"0.053\">love</span><span style=\"opacity: 0.80\"> for </span><span style=\"background-color: hsl(0, 100.00%, 98.02%); opacity: 0.80\" title=\"-0.010\">douglas</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.64%); opacity: 0.81\" title=\"0.021\">hall</span><span style=\"opacity: 0.80\"> is at once </span><span style=\"background-color: hsl(120, 100.00%, 95.58%); opacity: 0.81\" title=\"0.031\">satisfying</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 99.64%); opacity: 0.80\" title=\"-0.001\">wrenching</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(120, 100.00%, 92.08%); opacity: 0.82\" title=\"0.071\">intellectually</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.89%); opacity: 0.84\" title=\"0.147\">challenging</span><span style=\"opacity: 0.80\"> . in its </span><span style=\"background-color: hsl(120, 100.00%, 93.97%); opacity: 0.81\" title=\"0.048\">final</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.88%); opacity: 0.84\" title=\"-0.147\">moments</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 96.66%); opacity: 0.81\" title=\"0.021\">film</span><span style=\"opacity: 0.80\"> even </span><span style=\"background-color: hsl(120, 100.00%, 89.83%); opacity: 0.83\" title=\"0.102\">takes</span><span style=\"opacity: 0.80\"> on itself , when </span><span style=\"background-color: hsl(120, 100.00%, 79.59%); opacity: 0.88\" title=\"0.276\">david</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 95.91%); opacity: 0.81\" title=\"0.028\">jane</span><span style=\"opacity: 0.80\"> &#x27; s </span><span style=\"background-color: hsl(120, 100.00%, 91.63%); opacity: 0.82\" title=\"0.077\">husband</span><span style=\"opacity: 0.80\"> , who has </span><span style=\"background-color: hsl(0, 100.00%, 95.81%); opacity: 0.81\" title=\"-0.029\">come</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 76.93%); opacity: 0.89\" title=\"0.329\">enjoy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.87%); opacity: 0.84\" title=\"-0.147\">killing</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 96.52%); opacity: 0.81\" title=\"0.022\">accuses</span><span style=\"opacity: 0.80\"> her of being the </span><span style=\"background-color: hsl(120, 100.00%, 88.41%); opacity: 0.83\" title=\"0.123\">sick</span><span style=\"opacity: 0.80\"> one . although there is a </span><span style=\"background-color: hsl(120, 100.00%, 99.86%); opacity: 0.80\" title=\"0.000\">victory</span><span style=\"opacity: 0.80\"> for the </span><span style=\"background-color: hsl(120, 100.00%, 90.19%); opacity: 0.83\" title=\"0.097\">leading</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.06%); opacity: 0.80\" title=\"-0.010\">characters</span><span style=\"opacity: 0.80\"> , this </span><span style=\"background-color: hsl(120, 100.00%, 87.87%); opacity: 0.84\" title=\"0.131\">resolution</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.21%); opacity: 0.80\" title=\"0.016\">suggests</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 87.02%); opacity: 0.84\" title=\"0.145\">disturbing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.05%); opacity: 0.80\" title=\"-0.010\">element</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(120, 100.00%, 93.46%); opacity: 0.82\" title=\"0.054\">fantasy</span><span style=\"opacity: 0.80\"> in </span><span style=\"background-color: hsl(120, 100.00%, 95.91%); opacity: 0.81\" title=\"0.028\">jane</span><span style=\"opacity: 0.80\"> , and thus a </span><span style=\"background-color: hsl(0, 100.00%, 95.39%); opacity: 0.81\" title=\"-0.033\">deep</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(0, 100.00%, 91.14%); opacity: 0.82\" title=\"-0.084\">seated</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.38%); opacity: 0.85\" title=\"-0.171\">character</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.05%); opacity: 0.81\" title=\"-0.036\">flaw</span><span style=\"opacity: 0.80\"> . in </span><span style=\"background-color: hsl(0, 100.00%, 94.47%); opacity: 0.81\" title=\"-0.043\">fact</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 99.97%); opacity: 0.80\" title=\"0.000\">hannon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.78%); opacity: 0.80\" title=\"0.012\">fuller</span><span style=\"opacity: 0.80\"> &#x27; s </span><span style=\"background-color: hsl(120, 100.00%, 98.87%); opacity: 0.80\" title=\"0.004\">activities</span><span style=\"opacity: 0.80\"> in the </span><span style=\"background-color: hsl(0, 100.00%, 96.22%); opacity: 0.81\" title=\"-0.025\">simulated</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.86%); opacity: 0.82\" title=\"0.074\">world</span><span style=\"opacity: 0.80\"> , the </span><span style=\"background-color: hsl(120, 100.00%, 95.27%); opacity: 0.81\" title=\"0.034\">behavior</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(120, 100.00%, 95.91%); opacity: 0.81\" title=\"0.028\">jane</span><span style=\"opacity: 0.80\"> &#x27; s </span><span style=\"background-color: hsl(120, 100.00%, 91.63%); opacity: 0.82\" title=\"0.077\">husband</span><span style=\"opacity: 0.80\"> , and the </span><span style=\"background-color: hsl(120, 100.00%, 95.24%); opacity: 0.81\" title=\"0.034\">effects</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(120, 100.00%, 90.74%); opacity: 0.82\" title=\"0.089\">entering</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 98.03%); opacity: 0.80\" title=\"-0.010\">simulation</span><span style=\"opacity: 0.80\"> on </span><span style=\"background-color: hsl(0, 100.00%, 98.02%); opacity: 0.80\" title=\"-0.010\">douglas</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.64%); opacity: 0.81\" title=\"0.021\">hall</span><span style=\"opacity: 0.80\"> all </span><span style=\"background-color: hsl(0, 100.00%, 88.55%); opacity: 0.83\" title=\"-0.121\">hint</span><span style=\"opacity: 0.80\"> at </span><span style=\"background-color: hsl(120, 100.00%, 89.83%); opacity: 0.83\" title=\"0.102\">similar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.77%); opacity: 0.85\" title=\"0.165\">issues</span><span style=\"opacity: 0.80\"> with those </span><span style=\"background-color: hsl(0, 100.00%, 98.06%); opacity: 0.80\" title=\"-0.010\">characters</span><span style=\"opacity: 0.80\"> . this is not a </span><span style=\"background-color: hsl(120, 100.00%, 96.66%); opacity: 0.81\" title=\"0.021\">film</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(120, 100.00%, 93.92%); opacity: 0.81\" title=\"0.049\">good</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.98%); opacity: 0.90\" title=\"0.348\">people</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.52%); opacity: 0.80\" title=\"0.007\">beset</span><span style=\"opacity: 0.80\"> from without by </span><span style=\"background-color: hsl(120, 100.00%, 81.82%); opacity: 0.86\" title=\"0.234\">great</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.39%); opacity: 0.83\" title=\"0.123\">evil</span><span style=\"opacity: 0.80\"> . the </span><span style=\"background-color: hsl(120, 100.00%, 95.64%); opacity: 0.81\" title=\"0.030\">tragedy</span><span style=\"opacity: 0.80\"> is not in their </span><span style=\"background-color: hsl(0, 100.00%, 99.46%); opacity: 0.80\" title=\"-0.002\">stars</span><span style=\"opacity: 0.80\"> , but in themselves . the </span><span style=\"background-color: hsl(120, 100.00%, 98.37%); opacity: 0.80\" title=\"0.007\">major</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.40%); opacity: 0.85\" title=\"0.171\">actors</span><span style=\"opacity: 0.80\"> , all of whom are </span><span style=\"background-color: hsl(0, 100.00%, 91.84%); opacity: 0.82\" title=\"-0.074\">required</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(0, 100.00%, 89.20%); opacity: 0.83\" title=\"-0.111\">play</span><span style=\"opacity: 0.80\"> two or even three </span><span style=\"background-color: hsl(0, 100.00%, 91.33%); opacity: 0.82\" title=\"-0.081\">roles</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 96.69%); opacity: 0.81\" title=\"0.021\">perform</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.37%); opacity: 0.92\" title=\"0.447\">extremely</span><span style=\"opacity: 0.80\"> well . </span><span style=\"background-color: hsl(0, 100.00%, 99.04%); opacity: 0.80\" title=\"-0.003\">bierko</span><span style=\"opacity: 0.80\"> , who will be </span><span style=\"background-color: hsl(0, 100.00%, 82.86%); opacity: 0.86\" title=\"-0.215\">familiar</span><span style=\"opacity: 0.80\"> as the </span><span style=\"background-color: hsl(0, 100.00%, 94.31%); opacity: 0.81\" title=\"-0.045\">psycho</span><span style=\"opacity: 0.80\"> from </span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.005\">_the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.15%); opacity: 0.82\" title=\"-0.071\">long</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.18%); opacity: 0.84\" title=\"-0.142\">kiss</span><span style=\"opacity: 0.80\"> goodnight_ , is </span><span style=\"background-color: hsl(120, 100.00%, 76.79%); opacity: 0.89\" title=\"0.332\">outstanding</span><span style=\"opacity: 0.80\"> . d &#x27; </span><span style=\"background-color: hsl(120, 100.00%, 98.27%); opacity: 0.80\" title=\"0.008\">onofrio</span><span style=\"opacity: 0.80\"> as </span><span style=\"background-color: hsl(0, 100.00%, 97.88%); opacity: 0.80\" title=\"-0.011\">whitney</span><span style=\"opacity: 0.80\"> , who </span><span style=\"background-color: hsl(120, 100.00%, 87.68%); opacity: 0.84\" title=\"0.134\">plays</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 88.89%); opacity: 0.83\" title=\"0.116\">pivotal</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.76%); opacity: 0.81\" title=\"0.040\">role</span><span style=\"opacity: 0.80\"> in </span><span style=\"background-color: hsl(120, 100.00%, 95.12%); opacity: 0.81\" title=\"0.036\">support</span><span style=\"opacity: 0.80\"> , also </span><span style=\"background-color: hsl(120, 100.00%, 92.93%); opacity: 0.82\" title=\"0.061\">turns</span><span style=\"opacity: 0.80\"> in a </span><span style=\"background-color: hsl(120, 100.00%, 93.92%); opacity: 0.81\" title=\"0.049\">good</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.12%); opacity: 0.88\" title=\"0.285\">performance</span><span style=\"opacity: 0.80\"> . the </span><span style=\"background-color: hsl(120, 100.00%, 92.87%); opacity: 0.82\" title=\"0.061\">lovely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.96%); opacity: 0.81\" title=\"0.027\">gretchen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.48%); opacity: 0.80\" title=\"0.014\">mol</span><span style=\"opacity: 0.80\"> , whose </span><span style=\"background-color: hsl(120, 100.00%, 98.05%); opacity: 0.80\" title=\"0.010\">elegance</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 96.02%); opacity: 0.81\" title=\"0.027\">integrity</span><span style=\"opacity: 0.80\"> , and </span><span style=\"background-color: hsl(120, 100.00%, 97.00%); opacity: 0.80\" title=\"0.018\">determination</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.57%); opacity: 0.81\" title=\"-0.031\">suggest</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.20%); opacity: 0.83\" title=\"0.097\">bergman</span><span style=\"opacity: 0.80\"> in _casablanca_ , </span><span style=\"background-color: hsl(120, 100.00%, 76.44%); opacity: 0.89\" title=\"0.339\">does</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 81.31%); opacity: 0.87\" title=\"0.243\">wonderful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.36%); opacity: 0.91\" title=\"0.404\">job</span><span style=\"opacity: 0.80\"> . her </span><span style=\"background-color: hsl(0, 100.00%, 94.64%); opacity: 0.81\" title=\"-0.041\">voice</span><span style=\"opacity: 0.80\"> , however , </span><span style=\"background-color: hsl(0, 100.00%, 82.67%); opacity: 0.86\" title=\"-0.218\">lacks</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 92.60%); opacity: 0.82\" title=\"0.065\">necessary</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.22%); opacity: 0.82\" title=\"-0.070\">weight</span><span style=\"opacity: 0.80\"> at </span><span style=\"background-color: hsl(120, 100.00%, 95.88%); opacity: 0.81\" title=\"0.028\">times</span><span style=\"opacity: 0.80\"> . this could be because she was </span><span style=\"background-color: hsl(0, 100.00%, 73.46%); opacity: 0.91\" title=\"-0.401\">given</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.721\">worst</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.51%); opacity: 0.80\" title=\"0.007\">lines</span><span style=\"opacity: 0.80\"> in a </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.001\">movie</span><span style=\"opacity: 0.80\"> whose </span><span style=\"background-color: hsl(120, 100.00%, 98.37%); opacity: 0.80\" title=\"0.007\">major</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.59%); opacity: 0.81\" title=\"0.031\">weakness</span><span style=\"opacity: 0.80\"> is the </span><span style=\"background-color: hsl(0, 100.00%, 78.67%); opacity: 0.88\" title=\"-0.294\">script</span><span style=\"opacity: 0.80\"> . some </span><span style=\"background-color: hsl(120, 100.00%, 97.94%); opacity: 0.80\" title=\"0.010\">minor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.60%); opacity: 0.89\" title=\"0.335\">flaws</span><span style=\"opacity: 0.80\"> , hairline </span><span style=\"background-color: hsl(120, 100.00%, 97.45%); opacity: 0.80\" title=\"0.014\">cracks</span><span style=\"opacity: 0.80\"> in </span><span style=\"background-color: hsl(120, 100.00%, 84.31%); opacity: 0.85\" title=\"0.190\">fine</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.39%); opacity: 0.80\" title=\"0.007\">porcelain</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 92.94%); opacity: 0.82\" title=\"-0.061\">appear</span><span style=\"opacity: 0.80\"> in </span><span style=\"background-color: hsl(120, 100.00%, 87.05%); opacity: 0.84\" title=\"0.144\">places</span><span style=\"opacity: 0.80\"> . there are one or two </span><span style=\"background-color: hsl(0, 100.00%, 98.07%); opacity: 0.80\" title=\"-0.009\">instances</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 93.30%); opacity: 0.82\" title=\"-0.056\">jerky</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.72%); opacity: 0.87\" title=\"-0.236\">editing</span><span style=\"opacity: 0.80\"> . the </span><span style=\"background-color: hsl(0, 100.00%, 78.67%); opacity: 0.88\" title=\"-0.294\">script</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.83%); opacity: 0.83\" title=\"0.102\">takes</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 92.47%); opacity: 0.82\" title=\"0.066\">edge</span><span style=\"opacity: 0.80\"> off the </span><span style=\"background-color: hsl(120, 100.00%, 96.66%); opacity: 0.81\" title=\"0.021\">film</span><span style=\"opacity: 0.80\"> &#x27; s </span><span style=\"background-color: hsl(120, 100.00%, 93.20%); opacity: 0.82\" title=\"0.057\">climaxes</span><span style=\"opacity: 0.80\"> . the </span><span style=\"background-color: hsl(0, 100.00%, 98.15%); opacity: 0.80\" title=\"-0.009\">atmosphere</span><span style=\"opacity: 0.80\"> becomes too </span><span style=\"background-color: hsl(120, 100.00%, 95.46%); opacity: 0.81\" title=\"0.032\">claustrophobic</span><span style=\"opacity: 0.80\"> at </span><span style=\"background-color: hsl(120, 100.00%, 95.88%); opacity: 0.81\" title=\"0.028\">times</span><span style=\"opacity: 0.80\"> ( yet , there is a </span><span style=\"background-color: hsl(0, 100.00%, 90.78%); opacity: 0.82\" title=\"-0.089\">clue</span><span style=\"opacity: 0.80\"> there too ) . one </span><span style=\"background-color: hsl(120, 100.00%, 91.13%); opacity: 0.82\" title=\"0.084\">wonders</span><span style=\"opacity: 0.80\"> if even after two </span><span style=\"background-color: hsl(120, 100.00%, 92.05%); opacity: 0.82\" title=\"0.072\">decades</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 97.45%); opacity: 0.80\" title=\"-0.014\">_blade</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.43%); opacity: 0.80\" title=\"-0.007\">runner_</span><span style=\"opacity: 0.80\"> is still </span><span style=\"background-color: hsl(0, 100.00%, 97.74%); opacity: 0.80\" title=\"-0.012\">casting</span><span style=\"opacity: 0.80\"> its </span><span style=\"background-color: hsl(0, 100.00%, 92.15%); opacity: 0.82\" title=\"-0.071\">long</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.40%); opacity: 0.82\" title=\"-0.080\">shadow</span><span style=\"opacity: 0.80\"> over </span><span style=\"background-color: hsl(120, 100.00%, 95.61%); opacity: 0.81\" title=\"0.031\">sci</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.034\">fi</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.98%); opacity: 0.81\" title=\"0.027\">films</span><span style=\"opacity: 0.80\"> . one can see a </span><span style=\"background-color: hsl(120, 100.00%, 95.38%); opacity: 0.81\" title=\"0.033\">group</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(120, 100.00%, 99.90%); opacity: 0.80\" title=\"0.000\">suits</span><span style=\"opacity: 0.80\"> in their </span><span style=\"background-color: hsl(120, 100.00%, 94.68%); opacity: 0.81\" title=\"0.040\">suite</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 94.09%); opacity: 0.81\" title=\"-0.047\">waving</span><span style=\"opacity: 0.80\"> their </span><span style=\"background-color: hsl(0, 100.00%, 88.77%); opacity: 0.83\" title=\"-0.117\">hands</span><span style=\"opacity: 0.80\"> imperiously at </span><span style=\"background-color: hsl(120, 100.00%, 83.56%); opacity: 0.86\" title=\"0.203\">directors</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.79%); opacity: 0.88\" title=\"-0.272\">like</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 92.01%); opacity: 0.82\" title=\"0.072\">emperor</span><span style=\"opacity: 0.80\"> in _amadeus_ : &quot; </span><span style=\"background-color: hsl(0, 100.00%, 75.42%); opacity: 0.90\" title=\"-0.360\">make</span><span style=\"opacity: 0.80\"> it more like_blade </span><span style=\"background-color: hsl(0, 100.00%, 98.43%); opacity: 0.80\" title=\"-0.007\">runner_</span><span style=\"opacity: 0.80\"> , you </span><span style=\"background-color: hsl(0, 100.00%, 93.07%); opacity: 0.82\" title=\"-0.059\">know</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 91.42%); opacity: 0.82\" title=\"0.080\">dark</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 97.95%); opacity: 0.80\" title=\"-0.010\">rainy</span><span style=\"opacity: 0.80\"> . &quot; </span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.005\">_the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.00%); opacity: 0.81\" title=\"0.048\">thirteen</span><span style=\"opacity: 0.80\"> floor_ is that </span><span style=\"background-color: hsl(120, 100.00%, 80.83%); opacity: 0.87\" title=\"0.252\">rare</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.82%); opacity: 0.80\" title=\"-0.011\">exception</span><span style=\"opacity: 0.80\"> among </span><span style=\"background-color: hsl(0, 100.00%, 83.52%); opacity: 0.86\" title=\"-0.203\">hollywood</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.86%); opacity: 0.85\" title=\"0.163\">movies</span><span style=\"opacity: 0.80\"> : a , </span><span style=\"background-color: hsl(0, 100.00%, 92.80%); opacity: 0.82\" title=\"-0.062\">rich</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 88.70%); opacity: 0.83\" title=\"0.119\">emotionally</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.58%); opacity: 0.81\" title=\"0.031\">satisfying</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 84.11%); opacity: 0.85\" title=\"0.193\">intelligent</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.61%); opacity: 0.81\" title=\"0.031\">sci</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.034\">fi</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.001\">movie</span><span style=\"opacity: 0.80\"> . and yet , </span><span style=\"background-color: hsl(120, 100.00%, 93.83%); opacity: 0.81\" title=\"0.050\">ultimately</span><span style=\"opacity: 0.80\"> , it </span><span style=\"background-color: hsl(120, 100.00%, 96.61%); opacity: 0.81\" title=\"0.021\">proves</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 99.90%); opacity: 0.80\" title=\"0.000\">suits</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.96%); opacity: 0.90\" title=\"0.349\">right</span><span style=\"opacity: 0.80\"> . for when </span><span style=\"background-color: hsl(120, 100.00%, 93.92%); opacity: 0.81\" title=\"0.049\">good</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.61%); opacity: 0.81\" title=\"0.031\">sci</span><span style=\"opacity: 0.80\"> - </span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.034\">fi</span><span style=\"opacity: 0.80\"> is made , where is the </span><span style=\"background-color: hsl(0, 100.00%, 98.67%); opacity: 0.80\" title=\"-0.006\">sf</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.70%); opacity: 0.81\" title=\"0.051\">community</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.87%); opacity: 0.81\" title=\"-0.049\">turning</span><span style=\"opacity: 0.80\"> out in </span><span style=\"background-color: hsl(0, 100.00%, 98.08%); opacity: 0.80\" title=\"-0.009\">droves</span><span style=\"opacity: 0.80\"> to see it ? if we </span><span style=\"background-color: hsl(0, 100.00%, 98.18%); opacity: 0.80\" title=\"-0.009\">don</span><span style=\"opacity: 0.80\"> &#x27; t </span><span style=\"background-color: hsl(120, 100.00%, 95.12%); opacity: 0.81\" title=\"0.036\">support</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.82%); opacity: 0.86\" title=\"0.234\">great</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.67%); opacity: 0.80\" title=\"-0.006\">sf</span><span style=\"opacity: 0.80\"> , who will ?</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"]},"metadata":{},"execution_count":14}],"source":["item =16\n","item =18\n","\n","print ('Prediction: '+predicted_labels[item]+'; groud truth: '+test_labels[item])\n","eli5.show_prediction(classifier, test_corpus[item], vec=vectorizer)"]},{"cell_type":"markdown","metadata":{"id":"f8JZ7p7lbzYx"},"source":["If you've made it this far, you will have seen that the decisions are affected by words that are supposed to have a neutral semantic orientation. Open question: can you provide a few examples of such words?"]},{"cell_type":"markdown","metadata":{"id":"YkyZRZWSbzYy"},"source":["It seems reasonable to get the classifier to focus on sentiment words. Let's begin by extracting a list of positive words and a list of negative words as we did in Lab 3b. "]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"UXd5zYGLbzYy","executionInfo":{"status":"error","timestamp":1647095525147,"user_tz":-60,"elapsed":572,"user":{"displayName":"Florian Bär","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03438539089054973879"}},"outputId":"6b4f1037-eccc-4be2-bc5d-e065fae25f0f"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-f512be9f7d8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Words/positive-words.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopened\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcontents_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a+'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpositive_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontents_lines\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Words/positive-words.txt'"]}],"source":["with open('Words/positive-words.txt', errors='ignore') as opened:\n","    contents=opened.read()\n","contents_lines=['a+'] + contents.split('a+')[1].split('\\n')\n","\n","positive_words = [x for x in contents_lines if len(x)>0]\n","\n","\n","with open('Words/negative-words.txt', errors='ignore') as opened:\n","    contents=opened.read()\n","contents_lines=['2-faced'] + contents.split('2-faced')[1].split('\\n')\n","\n","negative_words = [x for x in contents_lines if len(x)>0]"]},{"cell_type":"markdown","metadata":{"id":"WGXV3IVWbzYz"},"source":["Now, let's write a function to remove non-sentiment tokens from our corpus. Once we have it, we'll run it on the training corpus and the test corpus to transform them into sentiment-only corpora. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9yQn2O7abzYz"},"outputs":[],"source":["# BEGIN_REMOVE\n","from nltk.tokenize import word_tokenize\n","\n","def remove_non_sentiment_tokens(corpus):\n","    sentiment_only_corpus=[]\n","    for document in corpus:\n","\n","        document_words = set(word for word in word_tokenize(document))\n","        sentiment_words = list(document_words.intersection(positive_words))+\\\n","                          list(document_words.intersection(negative_words))\n","        sentiment_only_corpus.append(' '.join(sentiment_words))\n","    return sentiment_only_corpus   \n","    \n","sentiment_only_training_corpus = remove_non_sentiment_tokens(training_corpus)\n","sentiment_only_test_corpus = remove_non_sentiment_tokens(test_corpus)\n","# END_REMOVE"]},{"cell_type":"markdown","metadata":{"id":"Y02vou3LbzYz"},"source":["Now, please train **maxent_pipeline** on the **sentiment_only_training_corpus** and test it on the **sentiment_only_test_corpus**."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"xtCULhIRbzY0","outputId":"1e52f9c2-44d8-42e1-c722-7693a8acbd07"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.835\n","              precision    recall  f1-score   support\n","\n","         neg       0.85      0.81      0.83       198\n","         pos       0.82      0.86      0.84       202\n","\n","    accuracy                           0.83       400\n","   macro avg       0.84      0.83      0.83       400\n","weighted avg       0.84      0.83      0.83       400\n","\n"]}],"source":["# BEGIN_REMOVE\n","maxent_pipeline.fit(sentiment_only_training_corpus, training_labels) \n","\n","predicted_labels = maxent_pipeline.predict(sentiment_only_test_corpus)\n","get_metrics(true_labels=test_labels,\n","        predicted_labels=predicted_labels)\n","# END_REMOVE"]},{"cell_type":"markdown","metadata":{"id":"KjezeyTpbzY0"},"source":["Open question: what do you think about the performance improvement? Is it greater than you expected, smaller than you expected, or just about what you expected? Why? "]}],"metadata":{"kernelspec":{"display_name":"py39","language":"python","name":"py39"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"colab":{"name":"MSE_AnTeDe_Lab3c_Supervised.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}